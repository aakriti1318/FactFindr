{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-02T20:44:54.295721Z","iopub.execute_input":"2023-04-02T20:44:54.296733Z","iopub.status.idle":"2023-04-02T20:44:54.322861Z","shell.execute_reply.started":"2023-04-02T20:44:54.296691Z","shell.execute_reply":"2023-04-02T20:44:54.321566Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/misinformation-fake-news-text-dataset-79k/EXTRA_RussianPropagandaSubset.csv\n/kaggle/input/misinformation-fake-news-text-dataset-79k/DataSet_Misinfo_TRUE.csv\n/kaggle/input/misinformation-fake-news-text-dataset-79k/DataSet_Misinfo_FAKE.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_fake = pd.read_csv('/kaggle/input/misinformation-fake-news-text-dataset-79k/DataSet_Misinfo_FAKE.csv')\ndf_true = pd.read_csv('/kaggle/input/misinformation-fake-news-text-dataset-79k/DataSet_Misinfo_TRUE.csv')\ndfr = pd.read_csv('/kaggle/input/misinformation-fake-news-text-dataset-79k/EXTRA_RussianPropagandaSubset.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:44:54.325369Z","iopub.execute_input":"2023-04-02T20:44:54.325981Z","iopub.status.idle":"2023-04-02T20:44:59.362666Z","shell.execute_reply.started":"2023-04-02T20:44:54.325940Z","shell.execute_reply":"2023-04-02T20:44:59.361551Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re\nimport spacy\nfrom textblob import TextBlob\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:44:59.364907Z","iopub.execute_input":"2023-04-02T20:44:59.365271Z","iopub.status.idle":"2023-04-02T20:45:20.801514Z","shell.execute_reply.started":"2023-04-02T20:44:59.365240Z","shell.execute_reply":"2023-04-02T20:45:20.800297Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df_fake.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:45:20.803346Z","iopub.execute_input":"2023-04-02T20:45:20.804150Z","iopub.status.idle":"2023-04-02T20:45:21.178540Z","shell.execute_reply.started":"2023-04-02T20:45:20.804116Z","shell.execute_reply":"2023-04-02T20:45:21.177330Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_true['label']=1\ndf_true=df_true.drop('Unnamed: 0',axis=1)\ndf_fake['label']=0\ndf_fake=df_fake.drop('Unnamed: 0',axis=1)\n\ndf = pd.concat([df_true, df_fake])","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:45:21.183783Z","iopub.execute_input":"2023-04-02T20:45:21.184216Z","iopub.status.idle":"2023-04-02T20:45:21.254523Z","shell.execute_reply.started":"2023-04-02T20:45:21.184174Z","shell.execute_reply":"2023-04-02T20:45:21.253178Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:45:21.257640Z","iopub.execute_input":"2023-04-02T20:45:21.258260Z","iopub.status.idle":"2023-04-02T20:45:21.279291Z","shell.execute_reply.started":"2023-04-02T20:45:21.258217Z","shell.execute_reply":"2023-04-02T20:45:21.278213Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  The head of a conservative Republican faction ...      1\n1  Transgender people will be allowed for the fir...      1\n2  The special counsel investigation of links bet...      1\n3  Trump campaign adviser George Papadopoulos tol...      1\n4  President Donald Trump called on the U.S. Post...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The head of a conservative Republican faction ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Transgender people will be allowed for the fir...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The special counsel investigation of links bet...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Trump campaign adviser George Papadopoulos tol...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>President Donald Trump called on the U.S. Post...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.dropna(subset=['text'], inplace=True)\ndf['text'] = df['text'].apply(lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))\ndf['text'] = df['text'].apply(lambda x: x.lower())\nstop_words = set(stopwords.words('english'))\ndf['text'] = df['text'].apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\ndf['text'] = df['text'].apply(lambda x: nltk.word_tokenize(x))","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:45:21.280782Z","iopub.execute_input":"2023-04-02T20:45:21.281944Z","iopub.status.idle":"2023-04-02T20:47:06.136394Z","shell.execute_reply.started":"2023-04-02T20:45:21.281890Z","shell.execute_reply":"2023-04-02T20:47:06.135197Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stemmer = PorterStemmer()\ndf['text'] = df['text'].apply(lambda x: [stemmer.stem(word) for word in x])\ndf['text'] = df['text'].apply(lambda x: ' '.join(word for word in x))\ndf['text'] = df['text'].apply(lambda x: re.sub('\\d+', '', x))","metadata":{"execution":{"iopub.status.busy":"2023-04-02T20:47:06.138751Z","iopub.execute_input":"2023-04-02T20:47:06.139708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extraction = spacy.load('en_core_web_sm')\n\ndef info(text):\n    if isinstance(text, str):\n        doc = extraction(text)\n        country = \"\"\n        org = \"\"\n        person = \"\"\n        for ent in doc.ents:\n            if ent.label_ == \"GPE\":\n                if not country:\n                    country = ent.text\n            elif ent.label_ == \"ORG\":\n                if not org:\n                    org = ent.text\n            elif ent.label_ == \"PERSON\":\n                if not person:\n                    person = ent.text\n        return pd.Series({'Country': country, 'Organization': org, 'Person': person})\n    else:\n        return pd.Series({'Country': \"\", 'Organization': \"\", 'Person': \"\"})\n\ndf[['Country', 'Organization', 'Person']] = df['text'].apply(info)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_words(text):\n    if isinstance(text, str):\n        return len(text.split())-2\n    else:\n        return 0\ndf['Count'] = df['text'].apply(count_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = df.groupby(['label', 'Person','Organization'])\ncounts = grouped.size()\ntop_15_counts = counts.sort_values(ascending=False).head(15)\ntop_15_df = pd.DataFrame({'counts': top_15_counts.values}, index=top_15_counts.index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.pie(top_15_df['counts'], labels=top_15_df.index, autopct='%1.1f%%')\nplt.title('Top 15 Occurrences of label, Person and Organization')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = df.groupby(['Country', 'Organization', 'Person'])\ncounts = grouped.size()\ntop_10_counts = counts.sort_values(ascending=False).head(15)\ntop_10_df = pd.DataFrame({'counts': top_10_counts.values}, index=top_10_counts.index)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.pie(top_10_df['counts'], labels=top_10_df.index, autopct='%1.1f%%')\nplt.title('Top 15 Occurrences of Country, Organization and Person')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_10_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = df.drop('label', axis = 1)\ny = df['label']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voc_size=5000","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"messages=x.copy()\nmessages.reset_index(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    print(i)\n    review = re.sub('[^a-zA-Z]', ' ', messages['text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"onehot_repr=[one_hot(words,voc_size)for words in corpus] \nonehot_repr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent_length=20\nembedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\nprint(embedded_docs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedded_docs[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nvoc_size=5000\nsent_length=20\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX_final=np.array(embedded_docs)\ny_final=np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33,random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dropout\n## Creating model\nembedding_vector_features=40\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict_classes(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}